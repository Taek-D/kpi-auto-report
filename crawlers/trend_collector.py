"""
ê²€ìƒ‰ íŠ¸ë Œë“œ ìˆ˜ì§‘ ëª¨ë“ˆ (Google Trends + Naver DataLab)
ì™¸ë¶€ ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Supabaseì— ì ì¬.
ë‘ API ëª¨ë‘ ì‹¤íŒ¨í•´ë„ ê¸°ì¡´ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¶„ì„ì€ ê³„ì† ê°€ëŠ¥.
"""

import logging
import os
import time
from datetime import datetime, timedelta

import requests

from .config import TREND_KEYWORDS
from .supabase_loader import SupabaseLoader

logger = logging.getLogger(__name__)


class TrendCollector:
    """Google Trends + Naver DataLab ê²€ìƒ‰ íŠ¸ë Œë“œ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.loader = SupabaseLoader()
        self.naver_client_id = os.getenv("NAVER_DATALAB_CLIENT_ID", "")
        self.naver_client_secret = os.getenv("NAVER_DATALAB_CLIENT_SECRET", "")

    def run(self) -> str:
        """ì „ì²´ íŠ¸ë Œë“œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸"""
        lines = [
            "ğŸ“ˆ ê²€ìƒ‰ íŠ¸ë Œë“œ ìˆ˜ì§‘",
            "=" * 55,
            "",
        ]

        all_records = []

        # 1. Google Trends ìˆ˜ì§‘
        google_records = self._collect_google_trends()
        all_records.extend(google_records)
        lines.append(f"  Google Trends: {len(google_records)}ê±´ ìˆ˜ì§‘")

        # 2. Naver DataLab ìˆ˜ì§‘
        naver_records = self._collect_naver_datalab()
        all_records.extend(naver_records)
        lines.append(f"  Naver DataLab: {len(naver_records)}ê±´ ìˆ˜ì§‘")

        # 3. Supabase ì ì¬
        if all_records:
            stats = self.loader.upsert_trends(all_records)
            lines.append(f"\n  ì ì¬ ê²°ê³¼: ì„±ê³µ {stats['success']}ê±´ / ì‹¤íŒ¨ {stats['failed']}ê±´")
        else:
            lines.append("\n  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            lines.append("  (ìƒ˜í”Œ ë°ì´í„°ë¡œ --trend ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤)")

        lines.append("")
        return "\n".join(lines)

    def _collect_google_trends(self) -> list[dict]:
        """Google Trends ë°ì´í„° ìˆ˜ì§‘ (pytrends)"""
        try:
            from pytrends.request import TrendReq
        except ImportError:
            logger.warning("[Google Trends] pytrends ë¯¸ì„¤ì¹˜. pip install pytrends")
            return []

        records = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)
        timeframe = f"{start_date.strftime('%Y-%m-%d')} {end_date.strftime('%Y-%m-%d')}"

        try:
            pytrends = TrendReq(hl="ko", tz=540)
        except Exception as e:
            logger.error(f"[Google Trends] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return []

        # ë¸Œëœë“œë³„ í‚¤ì›Œë“œë¥¼ 5ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
        all_keywords = []
        for brand, groups in TREND_KEYWORDS.items():
            for product_group, keyword in groups.items():
                all_keywords.append((brand, product_group, keyword))

        for i in range(0, len(all_keywords), 5):
            batch = all_keywords[i : i + 5]
            keywords = [kw for _, _, kw in batch]

            try:
                pytrends.build_payload(keywords, cat=0, timeframe=timeframe, geo="KR")
                df = pytrends.interest_over_time()

                if df.empty:
                    logger.warning(f"[Google Trends] ë°°ì¹˜ {i // 5 + 1}: ë°ì´í„° ì—†ìŒ")
                    continue

                for brand, product_group, keyword in batch:
                    if keyword not in df.columns:
                        continue

                    for date_idx, row in df.iterrows():
                        records.append({
                            "trend_date": date_idx.strftime("%Y-%m-%d"),
                            "brand": brand,
                            "product_group": product_group,
                            "keyword": keyword,
                            "source": "google_trends",
                            "trend_value": float(row[keyword]),
                        })

                logger.info(f"[Google Trends] ë°°ì¹˜ {i // 5 + 1}: {len(batch)}ê°œ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì™„ë£Œ")

            except Exception as e:
                logger.warning(f"[Google Trends] ë°°ì¹˜ {i // 5 + 1} ì‹¤íŒ¨ (graceful skip): {e}")

            # rate limiting
            if i + 5 < len(all_keywords):
                time.sleep(2)

        logger.info(f"[Google Trends] ì´ {len(records)}ê±´ ìˆ˜ì§‘")
        return records

    def _collect_naver_datalab(self) -> list[dict]:
        """Naver DataLab ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ìˆ˜ì§‘"""
        if not self.naver_client_id or not self.naver_client_secret:
            logger.warning("[Naver DataLab] NAVER_DATALAB_CLIENT_ID/SECRET ë¯¸ì„¤ì •")
            return []

        records = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)

        url = "https://openapi.naver.com/v1/datalab/search"
        headers = {
            "X-Naver-Client-Id": self.naver_client_id,
            "X-Naver-Client-Secret": self.naver_client_secret,
            "Content-Type": "application/json",
        }

        # í‚¤ì›Œë“œë¥¼ 5ê°œì”© ë°°ì¹˜ (API ì œí•œ)
        all_keywords = []
        for brand, groups in TREND_KEYWORDS.items():
            for product_group, keyword in groups.items():
                all_keywords.append((brand, product_group, keyword))

        for i in range(0, len(all_keywords), 5):
            batch = all_keywords[i : i + 5]

            keyword_groups = []
            for _, product_group, keyword in batch:
                keyword_groups.append({
                    "groupName": product_group,
                    "keywords": [keyword],
                })

            body = {
                "startDate": start_date.strftime("%Y-%m-%d"),
                "endDate": end_date.strftime("%Y-%m-%d"),
                "timeUnit": "date",
                "keywordGroups": keyword_groups,
            }

            try:
                response = requests.post(url, headers=headers, json=body, timeout=15)
                response.raise_for_status()
                data = response.json()

                for result in data.get("results", []):
                    group_name = result.get("title", "")

                    # group_nameìœ¼ë¡œ brand ë§¤ì¹­
                    matched = [(b, pg, kw) for b, pg, kw in batch if pg == group_name]
                    if not matched:
                        continue

                    brand, product_group, keyword = matched[0]

                    for point in result.get("data", []):
                        records.append({
                            "trend_date": point["period"],
                            "brand": brand,
                            "product_group": product_group,
                            "keyword": keyword,
                            "source": "naver_datalab",
                            "trend_value": float(point["ratio"]),
                        })

                logger.info(f"[Naver DataLab] ë°°ì¹˜ {i // 5 + 1}: {len(batch)}ê°œ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì™„ë£Œ")

            except requests.RequestException as e:
                logger.warning(f"[Naver DataLab] ë°°ì¹˜ {i // 5 + 1} ì‹¤íŒ¨ (graceful skip): {e}")

            # rate limiting
            if i + 5 < len(all_keywords):
                time.sleep(1)

        logger.info(f"[Naver DataLab] ì´ {len(records)}ê±´ ìˆ˜ì§‘")
        return records
