"""
ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë“ˆ (ML ê¸°ë°˜ Demand Forecasting)
ë¸Œëœë“œë³„ ì¼ì¼ ë§¤ì¶œì„ í•™ìŠµí•˜ì—¬ ë‹¤ìŒ 7ì¼ ì˜ˆì¸¡.
Feature Engineering + Random Forest + êµì°¨ ê²€ì¦ + Feature Importance ë¶„ì„.
(ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ê¸°ë°˜ â€” ì‹¤ë¬´ ìš´ì˜ ë°ì´í„° íˆ¬ì… ì‹œ ë™ì¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥)
"""

import logging
import math
from pathlib import Path

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder

from .supabase_loader import SupabaseLoader

logger = logging.getLogger(__name__)

OUTPUT_DIR = Path(__file__).parent.parent / "output"

BRAND_LABELS = {"minix": "ë¯¸ë‹‰ìŠ¤", "thome": "í†°", "protione": "í”„ë¡œí‹°ì›"}


def _setup_korean_font():
    font_candidates = ["Malgun Gothic", "NanumGothic", "AppleGothic", "DejaVu Sans"]
    available = {f.name for f in fm.fontManager.ttflist}
    for font_name in font_candidates:
        if font_name in available:
            plt.rcParams["font.family"] = font_name
            plt.rcParams["axes.unicode_minus"] = False
            return


_setup_korean_font()


class DemandForecaster:
    """ë¸Œëœë“œë³„ ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸

    íŒŒì´í”„ë¼ì¸: ë°ì´í„° ì¡°íšŒ â†’ Feature Engineering â†’ í•™ìŠµ/í‰ê°€ â†’ ì˜ˆì¸¡ â†’ ì‹œê°í™”
    ëª¨ë¸: Random Forest Regressor (í•´ì„ ê°€ëŠ¥ì„± + ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ)
    """

    def __init__(self):
        self.loader = SupabaseLoader()
        self.model = None
        self.le_brand = LabelEncoder()
        self.le_channel = LabelEncoder()
        self.feature_names = []

    def run(self) -> str:
        """ì „ì²´ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        raw_data = self.loader.fetch_brand_sales(days=60)
        if not raw_data:
            return "[ì˜ˆì¸¡] ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Supabase ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        df = pd.DataFrame(raw_data)
        df["sale_date"] = pd.to_datetime(df["sale_date"])
        for col in ["revenue", "orders", "ad_spend", "roas"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        lines = [
            "ğŸ“ˆ ë§¤ì¶œ ì˜ˆì¸¡ ë¶„ì„ (ML Demand Forecasting)",
            "â€» ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ê¸°ë°˜ | ì‹¤ë¬´ ìš´ì˜ ë°ì´í„° íˆ¬ì… ì‹œ ë™ì¼ íŒŒì´í”„ë¼ì¸ ì ìš© ê°€ëŠ¥",
            "=" * 60,
            "",
        ]

        # 1. ë°ì´í„° ìš”ì•½
        data_lines = self._data_summary(df)
        lines.extend(data_lines)

        # 2. Feature Engineering
        df_features = self._engineer_features(df)
        feat_lines = self._feature_summary(df_features)
        lines.extend(feat_lines)

        # 3. í•™ìŠµ / í‰ê°€
        train_lines, df_pred = self._train_evaluate(df_features)
        lines.extend(train_lines)

        # 4. ë¸Œëœë“œë³„ ì˜ˆì¸¡ ê²°ê³¼
        pred_lines = self._brand_predictions(df_features, df_pred)
        lines.extend(pred_lines)

        # 5. ì‹œê°í™”
        self._plot_actual_vs_predicted(df_pred)
        self._plot_feature_importance()
        lines.append("")
        lines.append("[ì°¨íŠ¸] output/forecast_actual_vs_pred.png - ì‹¤ì œ vs ì˜ˆì¸¡ ë§¤ì¶œ ë¹„êµ")
        lines.append("[ì°¨íŠ¸] output/forecast_feature_importance.png - Feature Importance Top 10")

        return "\n".join(lines)

    def _data_summary(self, df: pd.DataFrame) -> list[str]:
        """ë°ì´í„° ìš”ì•½"""
        lines = [
            "ğŸ“‹ ë°ì´í„° ìš”ì•½",
            "â”" * 50,
        ]
        date_min = df["sale_date"].min().strftime("%Y-%m-%d")
        date_max = df["sale_date"].max().strftime("%Y-%m-%d")
        n_days = df["sale_date"].nunique()
        n_brands = df["brand"].nunique()
        n_channels = df["channel"].nunique()

        lines.append(f"  ê¸°ê°„: {date_min} ~ {date_max} ({n_days}ì¼)")
        lines.append(f"  ë¸Œëœë“œ: {n_brands}ê°œ, ì±„ë„: {n_channels}ê°œ")
        lines.append(f"  ì´ ë ˆì½”ë“œ: {len(df):,}ê±´")

        for brand in sorted(df["brand"].unique()):
            label = BRAND_LABELS.get(brand, brand)
            brand_rev = df[df["brand"] == brand]["revenue"].sum()
            lines.append(f"    {label}: ì´ ë§¤ì¶œ â‚©{brand_rev/10000:,.0f}ë§Œ")

        lines.append("")
        return lines

    def _engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Feature Engineering"""
        df = df.copy()

        # ì‹œê°„ ê¸°ë°˜ features
        df["day_of_week"] = df["sale_date"].dt.dayofweek
        df["week_of_month"] = (df["sale_date"].dt.day - 1) // 7 + 1
        df["is_weekend"] = (df["day_of_week"] >= 5).astype(int)
        df["month"] = df["sale_date"].dt.month
        df["day_of_month"] = df["sale_date"].dt.day

        # ë¸Œëœë“œ/ì±„ë„ ì¸ì½”ë”©
        df["brand_enc"] = self.le_brand.fit_transform(df["brand"])
        df["channel_enc"] = self.le_channel.fit_transform(df["channel"])

        # Lag features (ë¸Œëœë“œ+ì±„ë„ ê·¸ë£¹ë³„)
        df = df.sort_values(["brand", "channel", "sale_date"])
        for lag in [1, 7]:
            df[f"revenue_lag_{lag}d"] = (
                df.groupby(["brand", "channel"])["revenue"]
                .shift(lag)
            )

        # Rolling mean (7ì¼ ì´ë™í‰ê· )
        df["revenue_rolling_7d"] = (
            df.groupby(["brand", "channel"])["revenue"]
            .transform(lambda x: x.rolling(7, min_periods=1).mean())
        )

        # ì±„ë„ ROASë¥¼ featureë¡œ í™œìš©
        df["roas_feature"] = df["roas"].fillna(0)

        # NaN í–‰ ì œê±° (lag featureë¡œ ì¸í•œ ì²« 7ì¼)
        df = df.dropna(subset=["revenue_lag_1d", "revenue_lag_7d"])

        return df

    def _feature_summary(self, df: pd.DataFrame) -> list[str]:
        """Feature Engineering ìš”ì•½"""
        self.feature_names = [
            "day_of_week", "week_of_month", "is_weekend", "month", "day_of_month",
            "brand_enc", "channel_enc",
            "revenue_lag_1d", "revenue_lag_7d", "revenue_rolling_7d",
            "roas_feature",
        ]
        lines = [
            "âš™ï¸ Feature Engineering",
            "â”" * 50,
            f"  ì´ Features: {len(self.feature_names)}ê°œ",
            f"  í•™ìŠµ ë°ì´í„°: {len(df):,}ê±´ (lag featureë¡œ ì¸í•œ ì´ˆê¸° ë°ì´í„° ì œì™¸)",
            "",
            "  Feature ëª©ë¡:",
            "    [ì‹œê°„] day_of_week, week_of_month, is_weekend, month, day_of_month",
            "    [ë²”ì£¼] brand_enc, channel_enc",
            "    [Lag]  revenue_lag_1d(ì „ì¼), revenue_lag_7d(ì „ì£¼ ë™ì¼ ìš”ì¼)",
            "    [í†µê³„] revenue_rolling_7d(7ì¼ ì´ë™í‰ê· )",
            "    [ë§ˆì¼€íŒ…] roas_feature(ê´‘ê³  ìˆ˜ìµë¥ )",
            "",
        ]
        return lines

    def _train_evaluate(self, df: pd.DataFrame) -> tuple[list[str], pd.DataFrame]:
        """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
        lines = [
            "ğŸ¤– ëª¨ë¸ í•™ìŠµ ë° í‰ê°€",
            "â”" * 50,
        ]

        X = df[self.feature_names].values
        y = df["revenue"].values

        # ì‹œê³„ì—´ íŠ¹ì„±ìƒ ìµœê·¼ 7ì¼ì„ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë¶„ë¦¬
        dates = df["sale_date"].unique()
        dates_sorted = np.sort(dates)
        test_cutoff = dates_sorted[-7]  # ìµœê·¼ 7ì¼

        train_mask = df["sale_date"] < test_cutoff
        test_mask = df["sale_date"] >= test_cutoff

        X_train, X_test = X[train_mask], X[test_mask]
        y_train, y_test = y[train_mask], y[test_mask]

        lines.append(f"  Train: {len(X_train):,}ê±´ | Test: {len(X_test):,}ê±´ (ìµœê·¼ 7ì¼)")
        lines.append(f"  ëª¨ë¸: Random Forest Regressor")
        lines.append(f"    n_estimators=100, max_depth=10, min_samples_leaf=3")

        # í•™ìŠµ
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_leaf=3,
            random_state=42,
            n_jobs=-1,
        )
        self.model.fit(X_train, y_train)

        # í‰ê°€
        y_pred = self.model.predict(X_test)

        mae = mean_absolute_error(y_test, y_pred)
        rmse = math.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        mape = np.mean(np.abs((y_test - y_pred) / np.where(y_test == 0, 1, y_test))) * 100

        lines.append(f"\n  ğŸ“Š Test Set í‰ê°€ ì§€í‘œ")
        lines.append(f"    MAE:  â‚©{mae:,.0f} (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)")
        lines.append(f"    RMSE: â‚©{rmse:,.0f} (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)")
        lines.append(f"    RÂ²:   {r2:.4f} (ê²°ì • ê³„ìˆ˜)")
        lines.append(f"    MAPE: {mape:.1f}% (í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨)")

        # êµì°¨ ê²€ì¦ (ì‹œê³„ì—´ì´ë¯€ë¡œ ì°¸ê³ ìš©)
        cv_scores = cross_val_score(
            RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_leaf=3, random_state=42),
            X_train, y_train, cv=5, scoring="r2",
        )
        lines.append(f"\n  ğŸ”„ 5-Fold Cross Validation (Train set)")
        lines.append(f"    RÂ² í‰ê· : {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
        lines.append(f"    ê° fold: {', '.join(f'{s:.3f}' for s in cv_scores)}")

        # RÂ² í•´ì„
        if r2 >= 0.9:
            interpretation = "ë§¤ìš° ìš°ìˆ˜ â€” ë§¤ì¶œ ë³€ë™ì˜ 90% ì´ìƒ ì„¤ëª…"
        elif r2 >= 0.7:
            interpretation = "ìš°ìˆ˜ â€” ì£¼ìš” íŒ¨í„´ í¬ì°© ì„±ê³µ"
        elif r2 >= 0.5:
            interpretation = "ë³´í†µ â€” ê¸°ë³¸ íŒ¨í„´ì€ í•™ìŠµ, ì¶”ê°€ feature í•„ìš”"
        else:
            interpretation = "ê°œì„  í•„ìš” â€” ì™¸ë¶€ ìš”ì¸(í”„ë¡œëª¨ì…˜, ë°©ì†¡ì¼) ë³€ìˆ˜ ì¶”ê°€ ê¶Œì¥"

        lines.append(f"\n  ğŸ’¡ ëª¨ë¸ í•´ì„: {interpretation}")

        # Feature Importance
        importances = self.model.feature_importances_
        feat_imp = sorted(
            zip(self.feature_names, importances),
            key=lambda x: x[1],
            reverse=True,
        )

        lines.append(f"\n  ğŸ† Feature Importance Top 5")
        for fname, imp in feat_imp[:5]:
            bar = "â–ˆ" * int(imp * 50)
            lines.append(f"    {fname:25s} {imp:.3f} {bar}")

        lines.append("")

        # ì˜ˆì¸¡ ê²°ê³¼ DataFrame
        df_test = df[test_mask].copy()
        df_test["predicted_revenue"] = y_pred

        return lines, df_test

    def _brand_predictions(self, df_full: pd.DataFrame, df_pred: pd.DataFrame) -> list[str]:
        """ë¸Œëœë“œë³„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½"""
        lines = [
            "ğŸ“Š ë¸Œëœë“œë³„ ì˜ˆì¸¡ ê²°ê³¼ (í…ŒìŠ¤íŠ¸ ê¸°ê°„)",
            "â”" * 50,
        ]

        for brand in sorted(df_pred["brand"].unique()):
            label = BRAND_LABELS.get(brand, brand)
            brand_data = df_pred[df_pred["brand"] == brand]

            actual_total = brand_data["revenue"].sum()
            pred_total = brand_data["predicted_revenue"].sum()
            error_pct = abs(pred_total - actual_total) / actual_total * 100 if actual_total > 0 else 0

            lines.append(f"\n  [{label}]")
            lines.append(f"    ì‹¤ì œ ë§¤ì¶œ í•©ê³„:   â‚©{actual_total/10000:,.0f}ë§Œ")
            lines.append(f"    ì˜ˆì¸¡ ë§¤ì¶œ í•©ê³„:   â‚©{pred_total/10000:,.0f}ë§Œ")
            lines.append(f"    ì˜¤ì°¨ìœ¨:           {error_pct:.1f}%")

            # ì±„ë„ë³„ ìƒì„¸
            for channel in sorted(brand_data["channel"].unique()):
                ch_data = brand_data[brand_data["channel"] == channel]
                ch_actual = ch_data["revenue"].mean()
                ch_pred = ch_data["predicted_revenue"].mean()
                lines.append(
                    f"      {channel:12s} ì‹¤ì œ â‚©{ch_actual/10000:,.1f}ë§Œ/ì¼ â†’ ì˜ˆì¸¡ â‚©{ch_pred/10000:,.1f}ë§Œ/ì¼"
                )

        # ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ì œì•ˆ
        lines.append(f"\n  ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©")
        lines.append(f"    1. ë‹¤ìŒ ì£¼ ì˜ˆìƒ ë§¤ì¶œ ê¸°ë°˜ ì¬ê³  ë°œì£¼ëŸ‰ ì‚¬ì „ ì¡°ì •")
        lines.append(f"    2. ì˜ˆì¸¡ ëŒ€ë¹„ ì‹¤ì  í•˜íšŒ ì‹œ ì´ìƒ íƒì§€ (ì˜ˆì¸¡ ê¸°ë°˜ ë™ì  ì„ê³„ê°’)")
        lines.append(f"    3. ì±„ë„ë³„ ì˜ˆì¸¡ ë§¤ì¶œë¡œ ê´‘ê³  ì˜ˆì‚° ì‚¬ì „ ë°°ë¶„ ìµœì í™”")
        lines.append(f"    4. ì‹¤ì œ ìš´ì˜ ì‹œ: í”„ë¡œëª¨ì…˜/ë°©ì†¡ì¼ feature ì¶”ê°€ë¡œ ì •í™•ë„ í–¥ìƒ ê°€ëŠ¥")
        lines.append("")

        return lines

    def _plot_actual_vs_predicted(self, df_pred: pd.DataFrame) -> None:
        """ì‹¤ì œ vs ì˜ˆì¸¡ ë§¤ì¶œ ë¹„êµ ì°¨íŠ¸"""
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        brands = sorted(df_pred["brand"].unique())
        fig, axes = plt.subplots(1, len(brands), figsize=(6 * len(brands), 5))
        if len(brands) == 1:
            axes = [axes]

        brand_colors = {"minix": "#FF6B35", "thome": "#4A90D9", "protione": "#7ED321"}

        for ax, brand in zip(axes, brands):
            label = BRAND_LABELS.get(brand, brand)
            brand_data = df_pred[df_pred["brand"] == brand]

            # ì±„ë„ í•©ì‚° ì¼ë³„ ë§¤ì¶œ
            daily = brand_data.groupby("sale_date").agg(
                actual=("revenue", "sum"),
                predicted=("predicted_revenue", "sum"),
            ).reset_index()

            color = brand_colors.get(brand, "#666")
            dates = daily["sale_date"]

            ax.bar(dates, daily["actual"] / 10000, alpha=0.6, color=color, label="ì‹¤ì œ", width=0.4)
            ax.plot(dates, daily["predicted"] / 10000, "o--", color="#E74C3C", label="ì˜ˆì¸¡", linewidth=2, markersize=8)

            ax.set_title(f"{label} ì‹¤ì œ vs ì˜ˆì¸¡ ë§¤ì¶œ", fontsize=12, fontweight="bold")
            ax.set_ylabel("ë§¤ì¶œ (ë§Œì›)")
            ax.legend(fontsize=9)
            ax.tick_params(axis="x", rotation=45)
            ax.grid(True, axis="y", alpha=0.3)

        plt.tight_layout()
        path = OUTPUT_DIR / "forecast_actual_vs_pred.png"
        fig.savefig(path, dpi=150, bbox_inches="tight")
        plt.close(fig)
        logger.info(f"[ì˜ˆì¸¡] ì‹¤ì œ vs ì˜ˆì¸¡ ì°¨íŠ¸ ì €ì¥: {path}")

    def _plot_feature_importance(self) -> None:
        """Feature Importance ì°¨íŠ¸"""
        if self.model is None:
            return

        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        importances = self.model.feature_importances_
        feat_imp = sorted(
            zip(self.feature_names, importances),
            key=lambda x: x[1],
            reverse=True,
        )[:10]

        names = [f[0] for f in feat_imp]
        values = [f[1] for f in feat_imp]

        # Feature ì´ë¦„ í•œê¸€ ë§¤í•‘
        name_map = {
            "revenue_lag_1d": "ì „ì¼ ë§¤ì¶œ",
            "revenue_lag_7d": "ì „ì£¼ ë™ìš”ì¼ ë§¤ì¶œ",
            "revenue_rolling_7d": "7ì¼ ì´ë™í‰ê· ",
            "day_of_week": "ìš”ì¼",
            "channel_enc": "ì±„ë„",
            "brand_enc": "ë¸Œëœë“œ",
            "is_weekend": "ì£¼ë§ ì—¬ë¶€",
            "week_of_month": "ì›” ë‚´ ì£¼ì°¨",
            "month": "ì›”",
            "day_of_month": "ì¼",
            "roas_feature": "ROAS",
        }
        display_names = [name_map.get(n, n) for n in names]

        fig, ax = plt.subplots(figsize=(10, 6))

        colors = ["#E74C3C" if v > 0.1 else "#3498DB" if v > 0.05 else "#95A5A6" for v in values]
        bars = ax.barh(range(len(names)), values, color=colors, edgecolor="white")

        ax.set_yticks(range(len(names)))
        ax.set_yticklabels(display_names, fontsize=11)
        ax.invert_yaxis()
        ax.set_xlabel("Importance", fontsize=11)
        ax.set_title("ë§¤ì¶œ ì˜ˆì¸¡ Feature Importance (Random Forest)", fontsize=13, fontweight="bold")

        # ê°’ í‘œì‹œ
        for bar, val in zip(bars, values):
            ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2,
                    f"{val:.3f}", va="center", fontsize=10)

        ax.grid(True, axis="x", alpha=0.3)

        plt.tight_layout()
        path = OUTPUT_DIR / "forecast_feature_importance.png"
        fig.savefig(path, dpi=150, bbox_inches="tight")
        plt.close(fig)
        logger.info(f"[ì˜ˆì¸¡] Feature Importance ì°¨íŠ¸ ì €ì¥: {path}")
